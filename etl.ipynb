{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "import requests\n",
    "import zipfile\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get('https://bit.ly/416WE1X')\n",
    "response.raise_for_status() # raise an error for bad status codes\n",
    "\n",
    "with zipfile.ZipFile(io.BytesIO(response.content)) as zip_file:\n",
    "    zip_file.extractall(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract():\n",
    "\n",
    "    # Read datasets\n",
    "    dataset1 = pd.read_csv('dataset1.csv')\n",
    "    dataset2 = pd.read_csv('dataset2.csv')\n",
    "    dataset3 = pd.read_csv('dataset3.csv')\n",
    "\n",
    "    # Calculate missing value percentages\n",
    "    missing1 = dataset1.isnull().mean() * 100\n",
    "    missing2 = dataset2.isnull().mean() * 100\n",
    "    missing3 = dataset3.isnull().mean() * 100\n",
    "\n",
    "    #return data types\n",
    "    dt_type1 = dataset1.info()\n",
    "    dt_type2 = dataset2.info()\n",
    "    dt_type3 = dataset3.info()\n",
    "\n",
    "\n",
    "    return (dataset1, missing1, dt_type1), (dataset2, missing2,dt_type2), (dataset3, missing3, dt_type3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15 entries, 0 to 14\n",
      "Data columns (total 7 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   customer_id          15 non-null     int64 \n",
      " 1   date_of_purchase     15 non-null     object\n",
      " 2   total_amount_billed  15 non-null     int64 \n",
      " 3   payment_status       15 non-null     object\n",
      " 4   payment_method       15 non-null     object\n",
      " 5   promo_code           12 non-null     object\n",
      " 6   country_of_purchase  15 non-null     object\n",
      "dtypes: int64(2), object(5)\n",
      "memory usage: 972.0+ bytes\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15 entries, 0 to 14\n",
      "Data columns (total 7 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   customer_id         15 non-null     int64 \n",
      " 1   date_of_payment     15 non-null     object\n",
      " 2   amount_paid         15 non-null     int64 \n",
      " 3   payment_method      15 non-null     object\n",
      " 4   payment_status      15 non-null     object\n",
      " 5   late_payment_fee    15 non-null     int64 \n",
      " 6   country_of_payment  15 non-null     object\n",
      "dtypes: int64(3), object(4)\n",
      "memory usage: 972.0+ bytes\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15 entries, 0 to 14\n",
      "Data columns (total 5 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   customer_id        15 non-null     int64 \n",
      " 1   date_of_refund     15 non-null     object\n",
      " 2   refund_amount      15 non-null     int64 \n",
      " 3   reason_for_refund  15 non-null     object\n",
      " 4   country_of_refund  15 non-null     object\n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 732.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "(dataset1, missing1, dt_type1), (dataset2, missing2,dt_type2), (dataset3, missing3, dt_type3) = extract()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see promo code in dataset1 has 20% missing values so we will replace the missing values with No Promo just incase one would want to analyze customer purchase behaviour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform():\n",
    "\n",
    "    #copy datasets for transformation\n",
    "    df1 = dataset1.copy()\n",
    "    df2 = dataset2.copy()\n",
    "    df3 = dataset3.copy()\n",
    "\n",
    "    # replace missing values in promo_code column with No Promo\n",
    "    # df1.fillna({'promo_code': 'No Promo'}, inplace = True)\n",
    "    df1['promo_code']= df1['promo_code'].fillna('No Promo')\n",
    "    \n",
    "\n",
    "    # change date column datatype to date\n",
    "    df1['date_of_purchase'] = pd.to_datetime(df1['date_of_purchase'], errors='coerce')\n",
    "    df2['date_of_payment'] = pd.to_datetime(df2['date_of_payment'], errors='coerce')\n",
    "    df3['date_of_refund'] = pd.to_datetime(df3['date_of_refund'], errors='coerce')\n",
    "\n",
    "    #merge datasets\n",
    "    df1.rename(columns={'country_of_purchase': 'country'}, inplace=True) # first rename country column because they are the same accross\n",
    "    df2.rename(columns={'country_of_payment': 'country'}, inplace=True) # first rename country column because they are the same accross\n",
    "    df3.rename(columns={'country_of_refund': 'country'}, inplace=True) # first rename country column because they are the same accross\n",
    "\n",
    "    # now merge df1 and df2 both on the customer_id and country column and payment_method\n",
    "    df1and2 = df1.merge(df2,on=['customer_id','country','payment_method'], how ='left') \n",
    "\n",
    "    # now merge df1and2 to df3 on the customer_id and country_of_purchase/payment/refund column\n",
    "    merged_df = df1and2.merge(df3, on = ['customer_id','country'], how='left')\n",
    "\n",
    "    return merged_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(data, filename='final_output.csv'):\n",
    "    data.to_csv(filename, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "load(merged_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
